{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import categorical_crossentropy, mae\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width, height, depth, classes):\n",
    "\t# initialize the input shape and channels dimension to be\n",
    "\t# \"channels last\" ordering\n",
    "\tinputShape = (height, width, depth)\n",
    "\tchanDim = -1\n",
    "\t# build the model using Keras' Sequential API\n",
    "\tmodel = Sequential([\n",
    "\t\t# CONV => RELU => BN => POOL layer set\n",
    "\t\tConv2D(16, (3, 3), padding=\"same\", input_shape=inputShape),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 2 => POOL layer set\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(32, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# (CONV => RELU => BN) * 3 => POOL layer set\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tConv2D(64, (3, 3), padding=\"same\"),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(axis=chanDim),\n",
    "\t\tMaxPooling2D(pool_size=(2, 2)),\n",
    "\t\t# first (and only) set of FC => RELU layers\n",
    "\t\tFlatten(),\n",
    "\t\tDense(256),\n",
    "\t\tActivation(\"relu\"),\n",
    "\t\tBatchNormalization(),\n",
    "\t\tDropout(0.5),\n",
    "\t\t# softmax classifier\n",
    "\t\tDense(classes),\n",
    "\t\tActivation(\"softmax\")\n",
    "\t])\n",
    "\t# return the built model to the calling function\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(X, y):\n",
    "\t# keep track of our gradients\n",
    "\twith tf.GradientTape() as tape:\n",
    "\t\t# make a prediction using the model and then calculate the\n",
    "\t\t# loss\n",
    "\t\tpred = model(X)\n",
    "\t\tloss = categorical_crossentropy(y, pred)\n",
    "\t# calculate the gradients using our tape and then update the\n",
    "\t# model weights\n",
    "\tgrads = tape.gradient(loss, model.trainable_variables)\n",
    "\treturn grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading MNIST dataset...\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "BS = 64\n",
    "INIT_LR = 1e-3\n",
    "# load the MNIST dataset\n",
    "print(\"[INFO] loading MNIST dataset...\")\n",
    "((trainX, trainY), (testX, testY)) = mnist.load_data()\n",
    "# add a channel dimension to every image in the dataset, then scale\n",
    "# the pixel intensities to the range [0, 1]\n",
    "trainX = np.expand_dims(trainX, axis=-1)\n",
    "testX = np.expand_dims(testX, axis=-1)\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0\n",
    "# one-hot encode the labels\n",
    "trainY = to_categorical(trainY, 10)\n",
    "testY = to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] creating model...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] creating model...\")\n",
    "model = build_model(28, 28, 1, 10)\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] starting epoch 1/2...took 0.8817 minutes\n",
      "[INFO] starting epoch 2/2...took 0.9077 minutes\n"
     ]
    }
   ],
   "source": [
    "numUpdates = int(trainX.shape[0] / BS)\n",
    "# loop over the number of epochs\n",
    "steps_for_update = 200\n",
    "counter = 0\n",
    "for epoch in range(0, EPOCHS):\n",
    "\t# show the current epoch number\n",
    "\tprint(\"[INFO] starting epoch {}/{}...\".format(\n",
    "\t\tepoch + 1, EPOCHS), end=\"\")\n",
    "\tsys.stdout.flush()\n",
    "\tepochStart = time.time()\n",
    "\t# loop over the data in batch size increments\n",
    "\tfor i in range(0, numUpdates):\n",
    "\t\t# determine starting and ending slice indexes for the current\n",
    "\t\t# batch\n",
    "\t\tstart = i * BS\n",
    "\t\tend = start + BS\n",
    "\t\t# take a step\n",
    "\t\tif counter == 0:\n",
    "\t\t\tgrads = step(trainX[start:end], trainY[start:end])\n",
    "\t\telse:\n",
    "\t\t\tnew_grads = step(trainX[start:end], trainY[start:end])\n",
    "\t\t\tgrads = [(grads[i]*counter + new_grads[i])/(counter+1) for i in range(len(grads))]\n",
    "\t\tcounter += 1\n",
    "# \t\tprint(counter)\n",
    "\t\tif counter == steps_for_update:\n",
    "\t\t\topt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\t\t\tcounter = 0\n",
    "# \t\t\tprint('Weights updated')\n",
    "\tif counter > 0:\n",
    "\t\topt.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\t# show timing information for the epoch\n",
    "\tepochEnd = time.time()\n",
    "\telapsed = (epochEnd - epochStart) / 60.0\n",
    "\tprint(\"took {:.4} minutes\".format(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 200us/sample - loss: 0.0209 - acc: 0.9928\n",
      "[INFO] test accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "# in order to calculate accuracy using Keras' functions we first need\n",
    "# to compile the model\n",
    "model.compile(optimizer=opt, loss=categorical_crossentropy,\n",
    "\tmetrics=[\"acc\"])\n",
    "# now that the model is compiled we can compute the accuracy\n",
    "(loss, acc) = model.evaluate(testX, testY)\n",
    "print(\"[INFO] test accuracy: {:.4f}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numUpdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
